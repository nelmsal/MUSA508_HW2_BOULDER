---
title: "Assignment 2: Boulder County House Prices Algorithm"
author: "Gianluca Nelms and Alex Mangiapane"
date: "10/22/2021"
output: 
  bookdown::html_document2: 
    code_folding: hide
    fig_caption: yes
    toc: yes
editor_options: 
  markdown: 
    wrap: sentence
  chunk_output_type: console
---

# i. SCRAPS

## 3 Map of Closest Elementary Schools

This voronoi map of the closest Elementary School Distances shows that they are evenly geographically distributed with no home needing to go more than a few miles.

``` {r vornoi}
map_num = 3

boulder.sales.v = boulder.sales %>% 
  st_combine() %>% 
  st_voronoi() %>% 
  st_cast() %>%
  st_intersection(., boulder.county %>% st_union())

boulder.sales.vj = 
  boulder.sales.v %>% st_sf() %>%
  st_join(
    boulder.sales %>%
      select(ele.nn.id, ele.name, ele.nn.dist)
    )
boulder.sales.vj$ele.nn.id = boulder.sales.vj$ele.nn.id %>% as.integer()

###
boulder.sales.vj$ele.nn.dist.mi = boulder.sales.vj$ele.nn.dist / mile
var_field = 'ele.nn.dist.mi'

mx = max(boulder.sales.vj[[var_field]])
focus_length = length(unique(boulder.sales.vj[[var_field]]))
#breaks = c(0,1.5,2,2.5,4,20, mx)
#var_breaks = seq(0, ceiling(mx), by = .5)
var_breaks = c(0,.1,.25,.5,1,2, ceiling(mx))


boulder.sales.vj$ele.nn.dist.cut = 
  cutting_field(boulder.sales.vj[[var_field]], var_breaks)
breaks_length = length(unique(boulder.sales.vj$ele.nn.dist.cut))
pal = hcl.colors(breaks_length, alpha=.95, palette = "PurpOr")

###
boulder.county.2mi = boulder.county %>% st_buffer(2*mile)

ggplot() + 
  geom_county(fill='grey90',color=NA) +
  geom_sf(data = boulder.sales.vj, aes(fill = ele.nn.dist.cut), 
          colour = 'transparent', lwd=.2) +
  scale_fill_manual(
    values = pal, name='Miles to Nearest\nSchool to House', na.value = "grey90",
    labels = label_breaks(var_breaks)
    ) + 
  #geom_sf(data = col.elementary.pts, color='pink', lwd=0.3) + 
  geom_sf(data = boulder.schools, color='red',  lwd=0.5) + 
  geom_county() +
  geom_county(data = boulder.county.2mi, color='red') +
  geom_text_sf(sf_to_labels(
    boulder.cities %>% filter(incorporated=='city'), 'name')) + 
  labs(title = glue("Map {map_num}. Distance to Nearest Elementary School") + 
  plot_limits(data = boulder.county.2mi) + 
  mapTheme()
  
```


```{r predict_train_cv}




# fold75 = train.cv$control$indexOut$Resample075
# 
# boulder.predict.0.reg75 =
#   boulder.predict.0.cv[fold75, c("price", "price.predict")] %>%
#   mutate(
#     price.error = price.predict - price, 
#     price.abserror = abs(price.predict - price), 
#     price.ape = price.abserror / price
#     ) #%>% 
#   #filter(price < 5000000) 
# 
# ### ???
# train.cv.rs.min = train.cv$resample[75,]

# train.cv.MAPE = mean(boulder.predict.0.cv$price.ape, na.rm = T)
# train.cv.MAE = mean(boulder.predict.0.cv$price.abserror, na.rm = T)

```

``` {r corr_two}


multicollinear = c('tract.units.density', 'build.baths', 'build.house.sf')
low_corr = c('tract.rent', 'build.stories')
final_vars.ivs.cont = vars.ivs.cont[!vars.ivs.cont %in% 
                                          c(multicollinear, low_corr)]
corr_vars = c(var.dv, final_vars.ivs.cont)

boulder.cont = 
  boulder.predict.0 %>%
  select(corr_vars) %>% 
  st_drop_geometry(.)

ggcorr_full(boulder.cont #focus_vars = corr_vars
            )
```

```{r corr_predict0_vars, fig.width=10}

# fig_num = 2
# 
# boulder.cont = 
#   boulder.predict.0 %>%
#   select(c(var.dv, vars.ivs.cont)) %>% 
#   st_drop_geometry(.) %>%
#   select_if(., is.numeric)
# 
# corrmethod = 'pearson'
# 
# highlight = function(x, pat, color="black", family="") {
#   ifelse(grepl(pat, x), glue("<b style='font-family:{family}; color:{color}'>{x}</b>"), x)
# }
# 
# ggcorrplot(
#   cor(boulder.cont, method=corrmethod), # %>% round(1), 
#   p.mat = cor_pmat(boulder.cont, lab = TRUE, method = corrmethod),
#   colors = c("#6D9EC1", "white", "#E46726"),
#   type="lower",
#   lab=TRUE) +  
#   labs(
#     title = glue("Figure {fig_num}: Continuous Variables"),
#     subtitle = "Pearson Correlation") +
#   scale_y_discrete(labels= function(x) gsub("price","**price**", x))
# 
# # boulder.predict.0 %>%
# #   select(c('price', 'tract.units.density')) %>%
# #   st_drop_geometry() %>%
# #   ggplot(., aes(x=tract.units.density, y=price)) + 
# #     geom_point()+
# #     geom_smooth(method=lm)

```
# E.	Map of Dependent Variable (Sales Price)
*Develop 1 map of your dependent variable (sale price)*

## 1. Map Setup

```{r setup_map}


plot_limits = function(
  poly.geometry = boulder.cities$geometry,
  # buffer between plot's limits and the geometry 
  # (in unit of geometry column)
  buffer = 0
){
  # creates bounding box
  poly.bbox =
    poly.geometry %>% st_union() %>%
    # buffers the geometry so the ultimate plot has margins
    st_buffer(buffer) %>%
    st_bbox()
  return(
    # returns the 'coord_sf' function which you can add to any plot
    coord_sf(
      xlim = c(poly.bbox['xmin'], poly.bbox['xmax']),
      ylim = c(poly.bbox['ymin'], poly.bbox['ymax']),
      crs = st_crs(poly.geometry)
  ))}

get_labels = function(
  cut_breaks, round_digit = 0, bucket_diff=1, first_start_range=0, last_end_range=TRUE, input_end_range='', bucket_suffix='', bucket_prefix=''
){
  labels = 
    cut_breaks %>% gsub(",", " to ", .) %>% 
    str_sub(., 2, -2) %>% unique(.)
  
  list_str = function(l, remove=0){
      format(round(as.numeric(l), digit=round_digit)-remove, big.mark=",")}
  
  for (i in seq(from=1,to=length(labels))){
    bucket_range = labels[i] %>% str_split(., " to ")
    
    start_range = paste(bucket_prefix, list_str(bucket_range[[1]][1]))
    end_range = paste(list_str(bucket_range[[1]][2], remove=bucket_diff), bucket_suffix)
    
    if (i == 1 & first_start_range != ''){
      start_range = paste(bucket_prefix, list_str(first_start_range))}
    if (i == length(labels) & input_end_range!=''){
      end_range=paste(list_str(input_end_range), bucket_suffix)
      last_end_range=TRUE
      }
    if (i == length(labels) & last_end_range==FALSE){end_range='+'}
    
    bucket = paste(
        start_range, 
        'to', 
        end_range) %>% str_trim()
    labels[i] = bucket}
    
  return(labels)
  }



plot_vari_spec = function(
  focus_sf  = boulder.predict.0,
  variable  = "price",
  qbreaks   = q5(boulder.predict.0, "price"),
  bucket_diff = 1,
  title     = "Housing Price Variable", 
  subtitle  = "",
  legend_nm = "price",
  caption   = "",
  brewer_colors = 'Spectral',
  round_digit = 0,
  last_end_range = TRUE,
  input_end_range = '',
  bucket_suffix = '',
  buff_col = 'red',
  col_rev = FALSE,
  first_start_range = 0
){

cutting_field = function(var_field, var_breaks){return(var_field %>% cut(., breaks = var_breaks, dig.lab=10, include.lowest = TRUE))}

focus_sf$cut_field = cutting_field(focus_sf[[variable]], qbreaks)
  
cut_breaks = sapply(focus_sf$cut_field, function(brk) brk %>% levels())

labels = get_labels(
  cut_breaks, 
  round_digit = round_digit, bucket_diff = bucket_diff, 
  last_end_range = last_end_range, first_start_range = first_start_range, 
  input_end_range = input_end_range, bucket_suffix = bucket_suffix)

breaks_amount = length(qbreaks)-1
col_vals = brewer.pal(breaks_amount, name = brewer_colors)

if (col_rev==TRUE){col_vals=rev(col_vals)}

return(
ggplot()+
  # geom_sf(data = EB.all, fill=alpha('grey50', .5), color=alpha('grey50', .5)) + 
  # geom_sf(data = EB.back_water, fill=alpha('cornflowerblue', .5), color='transparent') + 
  # geom_sf(data  = EB.cities, fill='grey90')+
  geom_sf(
    data  = focus_sf, 
    aes(fill = cut_field), 
    color='grey50') +
  scale_fill_manual(
    values = col_vals,
    labels = labels, name = legend_nm) +
  # geom_sf(
  #   data=BART.buffers.TOD, fill='transparent', 
  #   color=alpha(buff_col, alpha=.75), lwd=.75) +
  # geom_sf(
  #   data=BART.stops, fill='white',
  #   color='grey30', shape=21) + 
  # geom_text(
  #   data=EB.labels, check_overlap=TRUE,
  #   size = 3.5, fontface='bold', color='black',
  #   aes(x=lon,y=lat, label=label)) + 
  labs(title    = title, 
       subtitle = subtitle,
       caption  = caption) +
  guides(fill = guide_legend(title.position="bottom", 
                             title.hjust = 0.5, title.vjust = 0)) + 
  theme(legend.position = "bottom",
        legend.spacing.x = unit(.1, 'in')) +
  # facet_wrap(~year)+
  mapTheme() #+ plot_limits()
)}

################
```


## 2. Map of Dependent Variable - Housing Prices 

Further to looking at the linear relationship between the variables, we also examine the spatial location and visual patterns between the predictor variables and house sales price through several maps. 

The map below shows the spatial distribution of house sales prices through Boulder County. 
```{r map_predict0_dv}

fig_num = 4

sub_fig_num = 0

variable  = "price"

filt_sf = 
  boulder.predict.0[
    !is.na(boulder.predict.0[[variable]]) &
      !is.infinite(boulder.predict.0[[variable]])
                       ,]
max_variable = max(filt_sf[[variable]])

#breaks = c(0,25,50,100, 150, max_variable)
breaks = seq(0, max_variable, length.out = 5)

plot_vari_spec(
  focus_sf  = filt_sf,
  variable  = variable,
  qbreaks   = breaks,
  title     = glue("Figure {fig_num}.{sub_fig_num} Home Prices"), 
  subtitle  = "",
  caption   = "",
  brewer_colors = 'OrRd',
  legend_nm = "Home Price",
  bucket_suffix = '  ',
  input_end_range = '',
  last_end_range = FALSE,
  round_digit=0,
  bucket_diff=1,
  first_start_range=0
)


# ggplot() +
#   # geom_sf(data = boulder.predict.0, 
#   #         fill = "gray80", color = "white") +
#   # geom_sf(data = boulder.predict.0, 
#   #         fill = "XXXXX", color = "XXXXXX") +
#   geom_sf(data = boulder.predict.0, 
#           aes(color = q5(price))) +
#   scale_color_manual(values = paletteMap) +
#   labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
#   mapTheme()


```

# F.	Maps of 3 Independent Variables
*Develop 3 maps of 3 of your most interesting independent variables.*


Next, we look at the spatial features of the the variables XXXX, XXXX, XXXX and XXXX.  Comment on where they look on the map, how its ditributed. 



```{r map_predict0_iv}

#maybe we can insert faded base map of boulder county?



for (
  variable_number in seq(1,3, by=1)
){
  plot_color = plot_colors[variable_number]
  variable_name = boulder.iv[variable_number]
  
  fm = 
  as.formula(paste(
    'price', "~", variable_name, sep=""))
  price_variable = lm(fm, data = boulder.predict.0)
  coefficient = 
    round(
      price_variable$coefficients[variable_name][1], 2)
  
  scat_plot = 
    ggplot(
      data = boulder.predict.0,
      aes(
        x = boulder.predict.0[[variable_name]],
        y = boulder.predict.0$price)) +
    geom_point(size=2, shape=20) +
    labs(title = 
           glue("Figure 2.{variable_number}: {variable_name}"),
         subtitle = glue("Coefficient = {coefficient}")
         ) +
    geom_smooth(method = "lm", se=F,
                color = plot_color) +
    xlab(variable_name) +
    ylab("price") +
    ylim(min(boulder.predict.0$price), ylim) + 
    plotTheme()
  print(scat_plot)
  
  variable_map = 
    ggplot() +
    geom_sf(
      data = boulder.predict.0, 
      aes(color =
        q5(boulder.predict.0[[variable_name]]))) +
    scale_color_manual(values = paletteMap) +
    labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
    mapTheme()
  print(variable_map)
}

# #variable 1
# ggplot() +
#   geom_sf(data = XXXX, fill = "gray80", color = "white") +
#   geom_sf(data = XXXX, fill = "XXXXX", color = "XXXXXX") +
#   geom_sf(data = boulder.predict.0, aes(color = q5(XXXXXX))) +
#   scale_color_manual(values = paletteMap) +
#   labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
#   mapTheme()
# 
# #variable 2
# ggplot() +
#   geom_sf(data = XXXX, fill = "gray80", color = "white") +
#   geom_sf(data = XXXX, fill = "XXXXX", color = "XXXXXX") +
#   geom_sf(data = boulder.predict.0, aes(color = q5(XXXXX))) +
#   scale_color_manual(values = paletteMap) +
#   labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
#   mapTheme()
# 
# #variable 3
# ggplot() +
#   geom_sf(data = XXXX, fill = "gray80", color = "white") +
#   geom_sf(data = XXXX, fill = "XXXXX", color = "XXXXXX") +
#   geom_sf(data = boulder.predict.0, aes(color = q5(XXXX))) +
#   scale_color_manual(values = paletteMap) +
#   labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
#   mapTheme()
# 
# #variable 4
# ggplot() +
#   geom_sf(data = XXXX, fill = "gray80", color = "white") +
#   geom_sf(data = XXXX, fill = "XXXXX", color = "XXXXXX") +
#   geom_sf(data = boulder.predict.0, aes(color = q5(XXXXX))) +
#   scale_color_manual(values = paletteMap) +
#   labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
#   mapTheme()


```




# 0. Introduction

Boulder County - population growing, Zillow wants us adjust their pricing algorithm to reflect now growing demand for houses.  

What are some aspects of Boulder County

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(RColorBrewer)
library(patchwork)
library(scales)
library(kableExtra)

library(tidycensus)
library(sf)
library(sp)
library(tmap)
#library(ggrepel)
library(tigris)


mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 16,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.text.x = element_text(size = 14))
}

plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 16,colour = "black"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "grey80", color = "white"),
    strip.text = element_text(size=12),
    
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    
    
    plot.background = element_blank(),
    
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    
    strip.text.x = element_text(size = 14)
  )
}


plot_limits = function(
  poly.geometry = '',
  # buffer between plot's limits and the geometry 
  # (in unit of geometry column)
  buffer = 0
){
  # creates bounding box
  poly.bbox =
    poly.geometry %>% st_union() %>%
    # buffers the geometry so the ultimate plot has margins
    st_buffer(buffer) %>%
    st_bbox()
  return(
    # returns the 'coord_sf' function which you can add to any plot
    coord_sf(
      xlim = c(poly.bbox['xmin'], poly.bbox['xmax']),
      ylim = c(poly.bbox['ymin'], poly.bbox['ymax']),
      crs = st_crs(poly.geometry)
  ))}

```

# 1. Data
## 1.A Gathering Data
*Briefly describe your methods for gathering the data.*

### 1.A.1 Import Data
```{r import}

col_crs = st_crs('ESRI:102653')

studentData_path =
  "data/studentData.geojson"
B.sales =
  st_read(studentData_path) %>% 
  st_set_crs('ESRI:102254') %>% 
  st_transform(., col_crs) 

parcel_path = 
  "data/Boulder_Parcels_20211009.geojson" 
B.par = st_read(parcel_path) %>%
  rename(ID = OBJECTID, APN=PARCEL_NO) %>%
  select(ID,APN) %>% 
  st_transform(., col_crs) %>% # North Col State Plane Feet
  mutate(
    geometry = st_make_valid(geometry), 
    area = st_area(geometry)) 
attributes(B.par$area) = NULL
B.par = B.par %>% filter(area>0)


ggplot() + geom_sf(data=B.sales)

address_path = 
  "data/Boulder_AddressPts_20211009.geojson"
B.add = st_read(address_path)%>% 
  st_transform(., col_crs)

acct_path = 
  "data/Account_Parcels.csv"
B.acct = read.csv(acct_path) 

build_path = 
  "data/Buildings.csv"
B.build = read.csv(build_path) 

land_path = 
  "data/Land.csv"
B.land = read.csv(land_path) 

owner_path = 
  "data/Owner_Address.csv"
B.owner = read.csv(owner_path) 

# permits = 
#   "data/Permits.csv"
# B.build = read.csv(build_path) 
```

### 1.A.2 Parcel Joins


```{r parcel}

glimpse(B.par)

```

### 1.A.3 Parcel Clean

```{r parcel_clean}

OG_len = nrow(B.par%>% st_drop_geometry())
APN_len = nrow(B.par %>% st_drop_geometry() %>% distinct(., APN))
ID_len = nrow(B.par %>% st_drop_geometry() %>% distinct(., ID, APN))
area_len = nrow(B.par[B.par$area>0,] %>% st_drop_geometry() )

print(OG_len)
print(OG_len-APN_len)
print(OG_len-ID_len)
print(OG_len-area_len)

B.par[(B.par$area<=0)&(B.par$APN %in% dupe_APN),]

n_occur = 
  data.frame(table(B.par$APN)) %>% 
  rename(APN=Var1) %>% arrange(-Freq)

dupe_APN = n_occur[n_occur$Freq > 1,"APN"]
B.dupe = 
  B.par[B.par$APN %in% dupe_APN,] %>% group_by(APN) %>%
  summarize(geometry = st_union(geometry))

B.par[(B.par$APN == "157505036006")&
        (st_area(B.par$geometry)>0),]



ggplot() + 
  geom_sf(data=B.par, lwd=.1) + 
  geom_sf(data=B.dupe, 
          fill='pink', color='red') + 
  plot_limits(poly.geometry= B.dupe)
```


### 1.A.99 Set Up Price Dataset

```{r price_dataset}

ID_fields = c("MUSA_ID")

variable_fields = c(
# 1. Num of Bedrooms
  "nbrBedRoom",
# 2. Main Square Foot
  "mainfloorSF",
# 3. Full Bathroom
  "nbrFullBaths"
)

B.data = B.sales[,c(ID_fields,variable_fields,'geometry')]

glimpse(B.data)
```


(this doesnt need to be in the report, but a method of filtering and transforming unon normal ly distributed data)

### Histogram
Plot histograms to assess Normalcy of Data. We don't need to add this in the report, but can be part of data wrangling or feature analysis. ANy that don't appear normal, look at the log transformed 
```{r histograms}

hist(variables, breaks=50)
hist(variables, breaks=50)
.
.
.
hist(variables, breaks=50)




```

### Set Up Regression

Split up the data between sales prices known, and the sales prices that are set to 0 to be predicted 

```{r data partition}

HousesPresent <- b.sales %>%
  filter(.,toPredict ==0)
HousesFuture <- b.sales %>%
  filter(., toPredict ==1)

```


## B.	Table of Summary Statistics
*Present a table of summary statistics with variable descriptions.*

*Sort these variables by their category (internal characteristics, amenities/public services or spatial structure).Check out the `stargazer` package for this.*

Table of summary Statistics 

```{r summary statistics}

b.salesSum <- b.sales %>%
  dplyr:: select(VARIABLES LIST)

b.salesSum <- st_drop_geomatry(B.salesSum)
stargazer(as.data.frame(b.salesSum), type="text", digits=1, title="Table1: Summary Statistics for Boulder COunty Housing", out = 'Boulder Data.txt")


```


## C.	Correlation Matrix
*Present a correlation matrix*

Correlation matrix to assess multicollinearity
see which variables have positive correlation, which variables have negative correlation, and which ones are correlated above 0.8 or negative 0.8, and if that happens, only choose one

```{r correlation matrix}

corrPlotVariables <- b.sales %>%
  dplyr::select(VARIABLES LIST)


numericVars <- 
  select_if(st_drop_geometry(corrPlotVariables), is.numeric) %>% na.omit()

ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
    labs(title = "Figure 1: Boulder Housing Correlation across Numeric Variables") 

```




```{r log transformed}

dataset$variable <- log(var)
.
.
.

dataset$variable <- Log(1+var)) --> #needed if there are any zeros in the dataset
```

```{r histograms of log transformed}

hist(lnvariables, breaks=50)
hist(lnvariables, breaks=50)
.
.
.
hist(lnvariables, breaks=50)

#if any variables still do not appear normal after log transform, then we will have to deicde if keeping them in or not. Obviously improtant variables (such as dependnet variable ho

```


## D.	Plots of Home Sales Price & 4 Independent Variables
*Present 4 home price correlation scatterplots that you think are of interest.*

*I’m going to look for interesting open data that you’ve integrated with the home sale observations*

Scatterplots of home price correlation that are of interest. 
Looking at interesting open data that we've integrated
```{r scatterplots}


#1 variable 

ggplot(data = HousesPresent, aes(x = PREDICTOR VARIABLE, y = SalePrice)) +
  geom_point(size=2, shape=20)  +
  labs(title = "Figure 2.1: XXXXXXXXX", subtitle = "XXXXXXXXXXXX") +
  geom_smooth(method = "lm", se=F, colour = "blue") +
  plotTheme()


#2 variable 

ggplot(data = HousesPresent, aes(x = PREDICTOR VARIABLE, y = SalePrice)) +
  geom_point(size=2, shape=20)  +
  labs(title = "Figure 2.1: XXXXXXXXX", subtitle = "XXXXXXXXXXXX") +
  geom_smooth(method = "lm", se=F, colour = "green") +
  plotTheme()

#3 variable 

ggplot(data = HousesPresent, aes(x = PREDICTOR VARIABLE, y = SalePrice)) +
  geom_point(size=2, shape=20)  +
  labs(title = "Figure 2.1: XXXXXXXXX", subtitle = "XXXXXXXXXXXX") +
  geom_smooth(method = "lm", se=F, colour = "red") +
  plotTheme()

#4 variable 

ggplot(data = HousesPresent, aes(x = PREDICTOR VARIABLE, y = SalePrice)) +
  geom_point(size=2, shape=20)  +
  labs(title = "Figure 2.1: XXXXXXXXX", subtitle = "XXXXXXXXXXXX") +
  geom_smooth(method = "lm", se=F, colour = "orange") +
  plotTheme()

```


## E.	Map of Dependent Variable (Sales Price)
*Develop 1 map of your dependent variable (sale price)*

Map of Dependent Variable - Housing Prices 

```{r map of dependent variable}

#maybe we can insert faded base map of boulder county?

ggplot() +
  geom_sf(data = XXXX, fill = "gray80", colour = "white") +
  geom_sf(data = XXXX, fill = "XXXXX", colour = "XXXXXX") +
  geom_sf(data = HousesPresent, aes(colour = q5(SalePrice))) +
  scale_colour_manual(values = paletteMap) +
  labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
  mapTheme()


```


## F.	Maps of 3 Independent Variables
*Develop 3 maps of 3 of your most interesting independent variables.*
Map of independent Variables - XXXX, XXXX, XXXX, XXXX

```{r map of independent variable}

#maybe we can insert faded base map of boulder county?

#variable 1
ggplot() +
  geom_sf(data = XXXX, fill = "gray80", colour = "white") +
  geom_sf(data = XXXX, fill = "XXXXX", colour = "XXXXXX") +
  geom_sf(data = HousesPresent, aes(colour = q5(XXXXXX))) +
  scale_colour_manual(values = paletteMap) +
  labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
  mapTheme()

#variable 2
ggplot() +
  geom_sf(data = XXXX, fill = "gray80", colour = "white") +
  geom_sf(data = XXXX, fill = "XXXXX", colour = "XXXXXX") +
  geom_sf(data = HousesPresent, aes(colour = q5(XXXXX))) +
  scale_colour_manual(values = paletteMap) +
  labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
  mapTheme()

#variable 3
ggplot() +
  geom_sf(data = XXXX, fill = "gray80", colour = "white") +
  geom_sf(data = XXXX, fill = "XXXXX", colour = "XXXXXX") +
  geom_sf(data = HousesPresent, aes(colour = q5(XXXX))) +
  scale_colour_manual(values = paletteMap) +
  labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
  mapTheme()

#variable 4
ggplot() +
  geom_sf(data = XXXX, fill = "gray80", colour = "white") +
  geom_sf(data = XXXX, fill = "XXXXX", colour = "XXXXXX") +
  geom_sf(data = HousesPresent, aes(colour = q5(XXXXX))) +
  scale_colour_manual(values = paletteMap) +
  labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
  mapTheme()


```

## G. Assorted Figures
*Include any other maps/graphs/charts you think might be of interest.*


-------------------------------
# 2.	Methods

## 2.A.	Describe Method
*Briefly describe your method (remember who your audience is)*



# 3.	Results 

## A.	Interpret Results
*Briefly interpret each in the context of the Zillow use case*

### 3.A.1 Run the Regression

```{r run the regression}

fit <- lm(SalePrice ~ ., data = st_drop_geometry(HousesPresent) %>%
             dplyr::select(SalePrice...........VARIABLES))
```


## 3.B.	Split Training/Test
*Split the ‘toPredict’ == 0 into a separate training and test set using a 75/25 split.*

### 3.B.1 Setting up Test and Train datasets


```{r test and train datasets}

#need to create a type of neighborhoods data set i believe, and join it into our pricesKnown data set. 

#need the geometries in order to do the Moran's I test later, and to plot the points 

#need to paste in the variable columns that balances factors for categories acorss the trainign and test sets 

inTrain <- createDataPartition(
              y = paste(HousesPresent$XXXX, HousesPresent$XXXX....), 
              p = .75, list = FALSE)

boulder.training <- HousesPresent[inTrain,] 
boulder.test <- HousesPresent[-inTrain,]  

```


### 3.B.2 Testing & Plotting Regression

```{r regression testing}

boulder.test <-
  boulder.test %>%
  mutate(Regression = "Baseline Regression",
         SalePrice.Predict = predict(fit.training, boulder.test), 
         SalePrice.Error = SalePrice.Predict - SalePrice, 
         SalePrice.AbsError = abs(SalePrice.Predict - SalePrice), 
         SalePrice.APE = SalePrice.AbsError / SalePrice) %>%   
  filter(SalePrice < 5000000) 

#Mean Error and APE 

mean(boulder.test$SalePrice.AbsError, na.rm = T)#[1] 351280.6
mean(boulder.test$SalePrice.APE, na.rm = T)#[1] 0.7101703
mean(boulder.test$SalePrice.Predict, na.rm = T)


ggplot(data = boulder.test) +
  geom_point(aes(x = SalePrice, y = SalePrice.AbsError)) +
  labs(title = "Figure XX Observed Sale Price and Absolute Error") +
  plotTheme()

ggplot(data = boulder.test) +
  geom_point(aes(x = SalePrice, y = SalePrice.APE)) +
  labs(title = "Figure XX: Observed Sale Price with Absolute Percent Error") +
  plotTheme()

```

#### 3.B.2.A K-Fold Test 
**where should this go?**

Testing for generalization 
Comparing mean average error of K-fold output with our model above that we trained 

```{r k-fold cross-validation}

fitControl <- trainControl(method = "cv", number = 100)
set.seed(825)


fit.cv <- 
  train(SalePrice ~ ., data = st_drop_geometry(HousesPresent) %>% 
                                dplyr::select(SalePrice, XXXXXXXXX), 
     method = "lm", trControl = fitControl, na.action = na.pass)

```

## C.	Table of lm Summary (Training)
*Provide a polished table of your (training set) lm summary results (coefficients, R2 etc).*

```{r regression table}

stargazer(fit.training, type="text", digits=1, title="Table 2: Boulder Trainign Data Regression Output", out = "Training LM.txt")

```

## D.	Table of MAE & MAPE (Test)
*Provide a polished table of mean absolute error and MAPE for a single test set.*
*Check out the “kable” function for markdown to create nice tables.*

## E.	Cross-Validation Test Results
*Provide the results of your cross-validation tests. This includes mean and standard deviation MAE. Do 100 folds and plot your cross-validation MAE as a histogram.*

*Is your model generalizable to new data?*

## F.	Plot Predicted Prices
*Plot predicted prices as a function of observed prices*

## G.	Map of Residuals (Test)
*1. Provide a map of your residuals for your test set*
*2. Include a Moran’s I test*
*3. Plot of the spatial lag in errors.*

### 3.G.1 Map of Test Residuals
```{r Map of test set residuals}

boulder.test$resid <- 
  boulder.test %>%
  as_data_frame() %>%
  add_residuals(., fit.training, var = "resid") %>%
  dplyr::select(resid, Folio) %>%
  pull(resid)


ggplot() +
geom_sf(data = XXXX, fill = "gray90", colour = "XXX") +
    geom_sf(data = XXXX, fill = "XXXX", colour = "XXXX") +
  geom_sf(data = boulder.test, aes(colour = q5(resid))) +
  scale_colour_manual(values = palette5) +
 labs(title = "Figure XXX: Test Set Residual Errors", subtitle = "XXXXX") +
  mapTheme()
```

### 3.G.2 Spatial Lag in Errors 

#### 3.G.2.A Set-Up
```{r Spatial Lag}
library(knitr)
library(kableExtra)
library(scales)

coords <- st_coordinates(HousesPresent)
neighborhoods <- knn2nb(knearneigh(coords, 5)) #the 5 nearest neighborhoods

spatialWeights <- nb2listw(neighborhoods, style="W") 
HousesPresent$lagPrice <- lag.listw(spatialWeights, HousesPresent$SalePrice)

coordinates.test <-  st_coordinates(boulder.test)
neighborList.test <- knn2nb(knearneigh(coordinates.test, 5))
spatialWeights.test <- nb2listw(neighborhoods.test, style="W")

```
#### 3.G.2.B Plot

```{r Plotting of Spatial Lag }


boulder.test %>%                
  mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)) %>%  
  ggplot(aes(lagPriceError, SalePrice)) +
  geom_point() +
  stat_smooth(aes(lagPriceError, SalePrice), 
             method = "lm", se = FALSE, size = 1, colour="#FA7800")+
  labs(title = "Figure XXX: Spatial Lag of Price Errors") +
  plotTheme() + theme(plot.title = element_text(size = 18, colour = "XXXX")) 
```

### 3.G.3 Moran's I

```{r Morans I}

BouldermoranTest <- moran.mc(boulder.test$SalePrice.Error,
                      spatialWeights.test, nsim = 999)


ggplot(as.data.frame(BouldermoranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = BouldermoranTest$statistic), colour = "#FA7800",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Figure XX: Observed and Permuted Moran's I",
       subtitle= "Observed Moran's I in orange",
       x="Moran's I",
       y="Count") +
  plotTheme()
```
## H.	Map of Predicted Values
*Provide a map of your predicted values for where ‘toPredict’ is both 0 and 1.*

```{r map of predicted values}

housespredicted <- b.sales %>%
  mutate(prediction = predict(reg.neighborhood, b.sales))

ggplot() +
  geom_sf(data = XXXX, fill = "gray90", colour = "white") +
    geom_sf(data = XXXX, fill = "XXXX", colour = "XXXXX") +
  geom_sf(data = housespredicted, aes(colour = q5(prediction))) +
 scale_colour_manual(values = palette5) +
 labs(title = "Figure XXX: Predicted House Price Values", subtitle = "Boulder County, CO") +
 # facet_wrap(~toPredict) +
  mapTheme()

```

## I. Map of MAPE by Neighborhood (Test)
*Using the test set predictions, provide a map of mean absolute percentage error (MAPE) by neighborhood.*

### I.1.A Accounting for neighborhood variance 

```{r Neighborhood variance into the Regression}

#Make regression model 

reg.neighborhood <- lm(SalePrice ~ ., data = as.data.frame(boulder.training) %>% 
                                 dplyr::select(XXXX_neighborhood name, SalePrice, XXXXXXXXXXxx))
#Outcomes
boulder.test.neighborhood <-
  boulder.test %>%
  mutate(Regression = "Neighborhood Effects",
         SalePrice.Predict = predict(reg.neighborhood, boulder.test), 
         SalePrice.Error = SalePrice - SalePrice.Predict,       
         SalePrice.AbsError = abs(SalePrice - SalePrice.Predict), 
         SalePrice.APE = (abs(SalePrice - SalePrice.Predict)) / SalePrice)%>% 
  filter(SalePrice < 5000000)


#accuracy

bothRegressions <-
  rbind(
    dplyr::select(boulder.test, starts_with("SalePrice"), Regression, neighborhood) %>%
      mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)),
    dplyr::select(boulder.test.nhood, starts_with("SalePrice"), Regression, XXXX_Neighborhood Name) %>%
      mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)))   


st_drop_geometry(bothRegressions) %>%
  gather(Variable, Value, -Regression, -neighborhood) %>%
  filter(Variable == "SalePrice.AbsError" | Variable == "SalePrice.APE") %>%
  group_by(Regression, Variable) %>%
    summarize(meanValue = mean(Value, na.rm = T)) %>%
    spread(Variable, meanValue) %>%
    kable(caption = "Table XX: Neighborhood Effect on Error")


```

### I.1.A Accounting for neighborhood variance 

```{r Plotting the predicted prices from the new neighborhood variance regression }

bothRegressions %>%
  dplyr::select(SalePrice.Predict, SalePrice, Regression) %>%
    ggplot(aes(SalePrice, SalePrice.Predict)) +
  geom_point() +
  stat_smooth(aes(SalePrice, SalePrice),
             method = "lm", se = FALSE, size = 1, colour="#FA7800") +
  stat_smooth(aes(SalePrice.Predict, SalePrice),
              method = "lm", se = FALSE, size = 1, colour="#25CB10") +
  facet_wrap(~Regression) +
  labs(title="Figure 10.1: Predicted Sale Price and Observed Price",
       subtitle="Orange line represents a perfect prediction; Green line represents prediction") +
  plotTheme() + theme(plot.title = element_text(size = 18, colour = "black"))

```

I.2 Map of MAPE by Neighborhoods

```{r Test Set Predictions, MAPE of neighborhoods}

names(bothRegressions)[names(bothRegressions) == "OUR NEGHBORHOOD NAME"] <- "Our Neighborhood values name"


st_drop_geometry(bothRegressions) %>%
  group_by(Regression, neighborhood) %>%
  summarise(mean.MAPE = mean(SalePrice.APE, na.rm = T)) %>%
  ungroup() %>%
  left_join(neighborhoods) %>%
    st_as_sf() %>%
   ggplot() +
    geom_sf(data = XXXX, fill = "XXXX", colour = "XXXX") +
      geom_sf(colour = "gray", aes(fill = q5(mean.MAPE))) +
      scale_fill_manual(values = paletteMap) +
  labs(title = "Figure XXX: MAPE by Neighborhood") +
      mapTheme()

```

## J.	Plot of MAPE by Neighborhood
*Provide a scatterplot plot of MAPE by neighborhood as a function of mean price by neighborhood.*


```{r  scatterplot plot of MAPE by neighborhood as a function of mean price by neighborhood}

scatter_neighborhood <-
    boulder.test.neighborhood %>%
    group_by(neighborhood) %>%
    dplyr::select(neighborhood, SalePrice.APE, SalePrice.Predict)


mean_scatter_neighborhood <-
  scatter_neighborhood %>%
  group_by(neighborhood) %>%
  summarise_at(vars("SalePrice.APE", "SalePrice.Predict"), mean)


plot(mean_scatter_neighborhood$SalePrice.Predict, mean_scatter_neighborhood$SalePrice.APE, main="Figure XXX: MAPE by Neighborhood and Mean Price by Neighborhood", xlab="Mean Price by Neighborhood", ylab="MAPE by neighborhood") +
  plotTheme()


```

## K.	Split City
*Using tidycensus, split your city into two groups (perhaps by race or income)*
*and test your model’s generalizability. Is your model generalizable?*
```{r Testing Model's Generalizability with race or income with Tidycensus}



```

----------------------------------
# 0. Introduction 


Boulder County - population growing, Zillow wants us adjust their pricing algorithm to reflect now growing demand for houses.  

WHat are some aspects of Boulder County




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(RColorBrewer)
library(patchwork)
library(scales)
library(kableExtra)

library(tidycensus)
library(sf)
library(sp)
library(tmap)
#library(ggrepel)
library(tigris)


mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 16,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.text.x = element_text(size = 14))
}

plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 16,colour = "black"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "grey80", color = "white"),
    strip.text = element_text(size=12),
    
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    
    
    plot.background = element_blank(),
    
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    
    strip.text.x = element_text(size = 14)
  )
}


plot_limits = function(
  poly.geometry = '',
  # buffer between plot's limits and the geometry 
  # (in unit of geometry column)
  buffer = 0
){
  # creates bounding box
  poly.bbox =
    poly.geometry %>% st_union() %>%
    # buffers the geometry so the ultimate plot has margins
    st_buffer(buffer) %>%
    st_bbox()
  return(
    # returns the 'coord_sf' function which you can add to any plot
    coord_sf(
      xlim = c(poly.bbox['xmin'], poly.bbox['xmax']),
      ylim = c(poly.bbox['ymin'], poly.bbox['ymax']),
      crs = st_crs(poly.geometry)
  ))}

```


# 1. Data







## 1.1 Import Data
Import Data

Sales Data

```{r import}

col_crs = st_crs('ESRI:102653')

parcel_path = 
  "data/Boulder_Parcels_20211009.geojson" 
B.par = st_read(parcel_path) %>%
  rename(ID = OBJECTID, APN=PARCEL_NO) %>%
  select(ID,APN) %>% 
  st_transform(., col_crs) %>% # North Col State Plane Feet
  mutate(
    geometry = st_make_valid(geometry), 
    area = st_area(geometry)) 
attributes(B.par$area) = NULL
B.par = B.par %>% filter(area>0)


studentData_path =
  "data/studentData.geojson"
B.sales =
  st_read(studentData_path) %>% 
  st_set_crs('ESRI:102254') %>% 
  st_transform(., col_crs) 

ggplot() + geom_sf(data=B.sales)

address_path = 
  "C:/Users/nelms/Documents/Code/Data/Boulder_AddressPts_20211009.geojson"
B.add = st_read(address_path)%>% 
  st_transform(., col_crs)

acct_path = 
  "C:/Users/nelms/Documents/Code/Data/Account_Parcels.csv"
B.acct = read.csv(acct_path) 

build_path = 
  "C:/Users/nelms/Documents/Code/Data/Buildings.csv"
B.build = read.csv(build_path) 

land_path = 
  "C:/Users/nelms/Documents/Code/Data/Land.csv"
B.land = read.csv(land_path) 

owner_path = 
  "C:/Users/nelms/Documents/Code/Data/Owner_Address.csv"
B.owner = read.csv(owner_path) 

# permits = 
#   "C:/Users/nelms/Documents/Code/Data/Permits.csv"
# B.build = read.csv(build_path) 
```

## Parcel Joins


```{r parcel}

glimpse(B.par)

```

## Parcel Clean

```{r parcel_clean}

OG_len = nrow(B.par%>% st_drop_geometry())
APN_len = nrow(B.par %>% st_drop_geometry() %>% distinct(., APN))
ID_len = nrow(B.par %>% st_drop_geometry() %>% distinct(., ID, APN))
area_len = nrow(B.par[B.par$area>0,] %>% st_drop_geometry() )

print(OG_len)
print(OG_len-APN_len)
print(OG_len-ID_len)
print(OG_len-area_len)

B.par[(B.par$area<=0)&(B.par$APN %in% dupe_APN),]

n_occur = 
  data.frame(table(B.par$APN)) %>% 
  rename(APN=Var1) %>% arrange(-Freq)

dupe_APN = n_occur[n_occur$Freq > 1,"APN"]
B.dupe = 
  B.par[B.par$APN %in% dupe_APN,] %>% group_by(APN) %>%
  summarize(geometry = st_union(geometry))

B.par[(B.par$APN == "157505036006")&
        (st_area(B.par$geometry)>0),]



ggplot() + 
  geom_sf(data=B.par, lwd=.1) + 
  geom_sf(data=B.dupe, 
          fill='pink', color='red') + 
  plot_limits(poly.geometry= B.dupe)
```


.....


Discuss briefly methods for gathering the data




(this doesnt need to be in the report, but a method of filterign and transforming unon normal ly distributed data)

Plot histograms to assess Normalcy of Data. We don't need to add this in the report, but can be part of data wrangling or feature analysis. ANy that don't appear normal, look at the log transformed 
```{r histograms}

hist(variables, breaks=50)
hist(variables, breaks=50)
.
.
.
hist(variables, breaks=50)




```

```{r log transformed}

dataset$variable <- log(var)
.
.
.

dataset$variable <- Log(1+var)) --> #needed if there are any zeros in the dataset
```

```{r histograms of log transformed}

hist(lnvariables, breaks=50)
hist(lnvariables, breaks=50)
.
.
.
hist(lnvariables, breaks=50)
#if any variables still do not appear normal after log transform, then we will have to deicde if keeping them in or not. Obviously improtant variables (such as dependnet variable ho

```


Set Up Regression

Split up the data between sales prices known, and the sales prices that are set to 0 to be predicted 

```{r data partition}

HousesPresent <- b.sales %>%
  filter(.,toPredict ==0)
HousesFuture <- b.sales %>%
  filter(., toPredict ==1)

```


Table of summary Statistics

```{r summary statistics}

b.salesSum <- b.sales %>%
  dplyr:: select(VARIABLES LIST)

b.salesSum <- st_drop_geomatry(B.salesSum)
stargazer(as.data.frame(b.salesSum), type="text", digits=1, title="Table1: Summary Statistics for Boulder COunty Housing", out = 'Boulder Data.txt")


```


#Correlation matrix to assess multicollinearity

see which variables have positive correlation, which variables have negative correlation, and which ones are correlated above 0.8 or negative 0.8, and if that happens, only choose one

```{r correlation matrix}

corrPlotVariables <- b.sales %>%
  dplyr::select(VARIABLES LIST)


numericVars <- 
  select_if(st_drop_geometry(corrPlotVariables), is.numeric) %>% na.omit()

ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
    labs(title = "Figure 1: Boulder Housing Correlation across Numeric Variables") 

```


Scatterplots of home price correlation that are of interest. Looking at interesting open data that we've integrated
```{r scatterplots}


#1 variable 

ggplot(data = HousesPresent, aes(x = PREDICTOR VARIABLE, y = SalePrice)) +
  geom_point(size=2, shape=20)  +
  labs(title = "Figure 2.1: XXXXXXXXX", subtitle = "XXXXXXXXXXXX") +
  geom_smooth(method = "lm", se=F, colour = "blue") +
  plotTheme()


#2 variable 

ggplot(data = HousesPresent, aes(x = PREDICTOR VARIABLE, y = SalePrice)) +
  geom_point(size=2, shape=20)  +
  labs(title = "Figure 2.1: XXXXXXXXX", subtitle = "XXXXXXXXXXXX") +
  geom_smooth(method = "lm", se=F, colour = "green") +
  plotTheme()

#3 variable 

ggplot(data = HousesPresent, aes(x = PREDICTOR VARIABLE, y = SalePrice)) +
  geom_point(size=2, shape=20)  +
  labs(title = "Figure 2.1: XXXXXXXXX", subtitle = "XXXXXXXXXXXX") +
  geom_smooth(method = "lm", se=F, colour = "red") +
  plotTheme()

#4 variable 

ggplot(data = HousesPresent, aes(x = PREDICTOR VARIABLE, y = SalePrice)) +
  geom_point(size=2, shape=20)  +
  labs(title = "Figure 2.1: XXXXXXXXX", subtitle = "XXXXXXXXXXXX") +
  geom_smooth(method = "lm", se=F, colour = "orange") +
  plotTheme()

```

Map of Dependent Variable - Housing Prices 

```{r map of dependent variable}

#maybe we can insert faded base map of boulder county?

ggplot() +
  geom_sf(data = XXXX, fill = "gray80", colour = "white") +
  geom_sf(data = XXXX, fill = "XXXXX", colour = "XXXXXX") +
  geom_sf(data = HousesPresent, aes(colour = q5(SalePrice))) +
  scale_colour_manual(values = paletteMap) +
  labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
  mapTheme()


```


Map of independent Variables - XXXX, XXXX, XXXX, XXXX

```{r map of independent variable}

#maybe we can insert faded base map of boulder county?

#variable 1
ggplot() +
  geom_sf(data = XXXX, fill = "gray80", colour = "white") +
  geom_sf(data = XXXX, fill = "XXXXX", colour = "XXXXXX") +
  geom_sf(data = HousesPresent, aes(colour = q5(XXXXXX))) +
  scale_colour_manual(values = paletteMap) +
  labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
  mapTheme()

#variable 2
ggplot() +
  geom_sf(data = XXXX, fill = "gray80", colour = "white") +
  geom_sf(data = XXXX, fill = "XXXXX", colour = "XXXXXX") +
  geom_sf(data = HousesPresent, aes(colour = q5(XXXXX))) +
  scale_colour_manual(values = paletteMap) +
  labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
  mapTheme()

#variable 3
ggplot() +
  geom_sf(data = XXXX, fill = "gray80", colour = "white") +
  geom_sf(data = XXXX, fill = "XXXXX", colour = "XXXXXX") +
  geom_sf(data = HousesPresent, aes(colour = q5(XXXX))) +
  scale_colour_manual(values = paletteMap) +
  labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
  mapTheme()

#variable 4
ggplot() +
  geom_sf(data = XXXX, fill = "gray80", colour = "white") +
  geom_sf(data = XXXX, fill = "XXXXX", colour = "XXXXXX") +
  geom_sf(data = HousesPresent, aes(colour = q5(XXXXX))) +
  scale_colour_manual(values = paletteMap) +
  labs(title = "XXXXXXXX", subtitle = "XXXXXXX") +
  mapTheme()


```


# 2.0 Methods

##2.1 Run the Regression

```{r run the regression}

fit <- lm(SalePrice ~ ., data = st_drop_geometry(HousesPresent) %>%
             dplyr::select(SalePrice...........VARIABLES))
```


##2.2Setting up Test and Train datasets


```{r test and train datasets}

#need to create a type of neighborhoods data set i believe, and join it into our pricesKnown data set. 

#need the geometries in order to do the Moran's I test later, and to plot the points 

#need to paste in the variable columns that balances factors for categories acorss the trainign and test sets 

inTrain <- createDataPartition(
              y = paste(HousesPresent$XXXX, HousesPresent$XXXX....), 
              p = .75, list = FALSE)

boulder.training <- HousesPresent[inTrain,] 
boulder.test <- HousesPresent[-inTrain,]  
 
```


##2.3 Training Regression
```{r regression training}

fit.training <- lm(salePrice~., data = st_drop_geometry(boulder.training)  %>% 
                             dplyr::select(SalePrice, XXXXXX))
```

#3.0 Results

##3.1 Summary Table 
```{r regression table}

stargazer(fit.training, type="text", digits=1, title="Table 2: Boulder Trainign Data Regression Output", out = "Training LM.txt")

```



##3.2 Test Regression and plot the results
```{r regression testing}

boulder.test <-
  boulder.test %>%
  mutate(Regression = "Baseline Regression",
         SalePrice.Predict = predict(fit.training, boulder.test), 
         SalePrice.Error = SalePrice.Predict - SalePrice, 
         SalePrice.AbsError = abs(SalePrice.Predict - SalePrice), 
         SalePrice.APE = SalePrice.AbsError / SalePrice) %>%   
  filter(SalePrice < 5000000) 

#Mean Error and APE 

mean(boulder.test$SalePrice.AbsError, na.rm = T)#[1] 351280.6
mean(boulder.test$SalePrice.APE, na.rm = T)#[1] 0.7101703
mean(boulder.test$SalePrice.Predict, na.rm = T)


ggplot(data = boulder.test) +
  geom_point(aes(x = SalePrice, y = SalePrice.AbsError)) +
  labs(title = "Figure XX Observed Sale Price and Absolute Error") +
  plotTheme()

ggplot(data = boulder.test) +
  geom_point(aes(x = SalePrice, y = SalePrice.APE)) +
  labs(title = "Figure XX: Observed Sale Price with Absolute Percent Error") +
  plotTheme()


```

Testing for generalization 
Comparing mean average error of K-fold output with our model above that we trained 


##2.3 K-Fold Test 
```{r k-fold cross-validation}

fitControl <- trainControl(method = "cv", number = 100)
set.seed(825)


fit.cv <- 
  train(SalePrice ~ ., data = st_drop_geometry(HousesPresent) %>% 
                                dplyr::select(SalePrice, XXXXXXXXX), 
     method = "lm", trControl = fitControl, na.action = na.pass)

```


```{r MAP of test set residuals}


boulder.test$resid <- 
  boulder.test %>%
  as_data_frame() %>%
  add_residuals(., fit.training, var = "resid") %>%
  dplyr::select(resid, Folio) %>%
  pull(resid)


ggplot() +
geom_sf(data = XXXX, fill = "gray90", colour = "XXX") +
    geom_sf(data = XXXX, fill = "XXXX", colour = "XXXX") +
  geom_sf(data = boulder.test, aes(colour = q5(resid))) +
  scale_colour_manual(values = palette5) +
 labs(title = "Figure XXX: Test Set Residual Errors", subtitle = "XXXXX") +
  mapTheme()


```


Spatial Lag in Errors 

```{r Spatial Lag}
library(knitr)
library(kableExtra)
library(scales)

coords <- st_coordinates(HousesPresent)
neighborhoods <- knn2nb(knearneigh(coords, 5)) #the 5 nearest neighborhoods

spatialWeights <- nb2listw(neighborhoods, style="W") 
HousesPresent$lagPrice <- lag.listw(spatialWeights, HousesPresent$SalePrice)

coordinates.test <-  st_coordinates(boulder.test)
neighborList.test <- knn2nb(knearneigh(coordinates.test, 5))
spatialWeights.test <- nb2listw(neighborhoods.test, style="W")

```


```{r Plotting of Spatial Lag }


boulder.test %>%                
  mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)) %>%  
  ggplot(aes(lagPriceError, SalePrice)) +
  geom_point() +
  stat_smooth(aes(lagPriceError, SalePrice), 
             method = "lm", se = FALSE, size = 1, colour="#FA7800")+
  labs(title = "Figure XXX: Spatial Lag of Price Errors") +
  plotTheme() + theme(plot.title = element_text(size = 18, colour = "XXXX")) 
```


```{r Morans I}

BouldermoranTest <- moran.mc(boulder.test$SalePrice.Error,
                      spatialWeights.test, nsim = 999)


ggplot(as.data.frame(BouldermoranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = BouldermoranTest$statistic), colour = "#FA7800",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Figure XX: Observed and Permuted Moran's I",
       subtitle= "Observed Moran's I in orange",
       x="Moran's I",
       y="Count") +
  plotTheme()


```

##Accounting for neighborhood variance 

```{r Neighborhood variance into the Regression}

#Make regression model 

reg.neighborhood <- lm(SalePrice ~ ., data = as.data.frame(boulder.training) %>% 
                                 dplyr::select(XXXX_neighborhood name, SalePrice, XXXXXXXXXXxx))
#Outcomes
boulder.test.neighborhood <-
  boulder.test %>%
  mutate(Regression = "Neighborhood Effects",
         SalePrice.Predict = predict(reg.neighborhood, boulder.test), 
         SalePrice.Error = SalePrice - SalePrice.Predict,       
         SalePrice.AbsError = abs(SalePrice - SalePrice.Predict), 
         SalePrice.APE = (abs(SalePrice - SalePrice.Predict)) / SalePrice)%>% 
  filter(SalePrice < 5000000)


#accuracy

bothRegressions <-
  rbind(
    dplyr::select(boulder.test, starts_with("SalePrice"), Regression, neighborhood) %>%
      mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)),
    dplyr::select(boulder.test.nhood, starts_with("SalePrice"), Regression, XXXX_Neighborhood Name) %>%
      mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)))   


st_drop_geometry(bothRegressions) %>%
  gather(Variable, Value, -Regression, -neighborhood) %>%
  filter(Variable == "SalePrice.AbsError" | Variable == "SalePrice.APE") %>%
  group_by(Regression, Variable) %>%
    summarize(meanValue = mean(Value, na.rm = T)) %>%
    spread(Variable, meanValue) %>%
    kable(caption = "Table XX: Neighborhood Effect on Error")


```

```{r Plotting the predicted prices from the new neighborhood variance regression }

bothRegressions %>%
  dplyr::select(SalePrice.Predict, SalePrice, Regression) %>%
    ggplot(aes(SalePrice, SalePrice.Predict)) +
  geom_point() +
  stat_smooth(aes(SalePrice, SalePrice),
             method = "lm", se = FALSE, size = 1, colour="#FA7800") +
  stat_smooth(aes(SalePrice.Predict, SalePrice),
              method = "lm", se = FALSE, size = 1, colour="#25CB10") +
  facet_wrap(~Regression) +
  labs(title="Figure 10.1: Predicted Sale Price and Observed Price",
       subtitle="Orange line represents a perfect prediction; Green line represents prediction") +
  plotTheme() + theme(plot.title = element_text(size = 18, colour = "black"))

```


```{r map of predicted values}

housespredicted <- b.sales %>%
  mutate(prediction = predict(reg.neighborhood, b.sales))

ggplot() +
  geom_sf(data = XXXX, fill = "gray90", colour = "white") +
    geom_sf(data = XXXX, fill = "XXXX", colour = "XXXXX") +
  geom_sf(data = housespredicted, aes(colour = q5(prediction))) +
 scale_colour_manual(values = palette5) +
 labs(title = "Figure XXX: Predicted House Price Values", subtitle = "Boulder County, CO") +
 # facet_wrap(~toPredict) +
  mapTheme()

```


```{r Test Set Predictions, MAPE of neighborhoods}

names(bothRegressions)[names(bothRegressions) == "OUR NEGHBORHOOD NAME"] <- "Our Neighborhood values name"


st_drop_geometry(bothRegressions) %>%
  group_by(Regression, neighborhood) %>%
  summarise(mean.MAPE = mean(SalePrice.APE, na.rm = T)) %>%
  ungroup() %>%
  left_join(neighborhoods) %>%
    st_as_sf() %>%
   ggplot() +
    geom_sf(data = XXXX, fill = "XXXX", colour = "XXXX") +
      geom_sf(colour = "gray", aes(fill = q5(mean.MAPE))) +
      scale_fill_manual(values = paletteMap) +
  labs(title = "Figure XXX: MAPE by Neighborhood") +
      mapTheme()

```


```{r  scatterplot plot of MAPE by neighborhood as a function of mean price by neighborhood}

scatter_neighborhood <-
    boulder.test.neighborhood %>%
    group_by(neighborhood) %>%
    dplyr::select(neighborhood, SalePrice.APE, SalePrice.Predict)


mean_scatter_neighborhood <-
  scatter_neighborhood %>%
  group_by(neighborhood) %>%
  summarise_at(vars("SalePrice.APE", "SalePrice.Predict"), mean)


plot(mean_scatter_neighborhood$SalePrice.Predict, mean_scatter_neighborhood$SalePrice.APE, main="Figure XXX: MAPE by Neighborhood and Mean Price by Neighborhood", xlab="Mean Price by Neighborhood", ylab="MAPE by neighborhood") +
  plotTheme()


```



```{r Testing Model's Generalizability with race or income with Tidycensus}



```
