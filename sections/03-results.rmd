# 3.	Results 

## A.	Method
*Briefly interpret each in the context of the Zillow use case*

### 1. Interpret Results


## B.	Partition Training & Test Sets

Before developing the model, this study splits the dataset of known home prices [boulder.predict.0] before training a linear model so we can test that model on unbiased data. Specifically, 75% of the known home prices are randomly split into the training dataset [boulder.train] -- while 25% goes into an unbiased test set [boulder.test].


```{r partition_train_test}

# produces:
#   boulder.train
#   boulder.test

select_v = function(sf, variable_names=c('price', boulder.iv)){
  return(sf %>% st_drop_geometry(.) %>%
             select(variable_names))}

select_iv = function(sf, variable_names=boulder.iv){
  return(sf %>% st_drop_geometry(.) %>%
             select(variable_names))}

#need the geometries in order to do the Moran's I test later, and to plot the points 

#need to paste in the variable columns that balances factors for categories across the training and test sets. Ken mentions this in Chapter 3 of the textbook

inTrain = createDataPartition(
              y = do.call(paste, c(
                boulder.predict.0 %>% select_iv(.)
                , sep=" ")), 
              p = .75, list = FALSE)

boulder.train = boulder.predict.0[inTrain,]

boulder.test  = boulder.predict.0[-inTrain,]  


```


## C. Train Model 

With a training set, the study can now build its initial training linear model [boulder.train.lm] based on the independent variables constructed in Section 1.

### 1. Fitting a Linear Model

```{r train_lm}


independent_variables = boulder.iv %>% sort() %>% list()

variables_str = 
  do.call(paste, c(boulder.iv %>% list(), collapse = "+"))

fm_equation = as.formula(paste(
  dependent_variable, variables_str, sep="~"))

print(fm_equation)

boulder.train.lm = 
  lm(
    fm_equation, 
    data = boulder.train %>% select_v(.))


```


### 2. Results

#### A. Summary Table

``` {r train_results}

stargazer(
  boulder.train.lm, type="text", digits=1, 
  title="Table 2: Boulder Training Data Regression Output", 
  out = "results/Training_LM.txt")

boulder.test =
  boulder.test %>%
  mutate(
    regression = "Boulder Test Regression",
     price.predict = predict(boulder.train.lm, boulder.test), 
     price.error = price.predict - price, 
     price.abserror = abs(price.predict - price), 
     price.ape = price.abserror / price
    ) 
  #   %>%   
  # filter(price < 5000000) 


# fit = lm(
#   price ~ ., data =
#     boulder.predict.0 %>% select_v(.)
#           )
# print(summary(fit))



```



#### B. Errors Table
*Provide a polished table of mean absolute error and MAPE for a single test set.*
*Check out the “kable” function for markdown to create nice tables.*


```{r Table of MAE and MAPE, message=FALSE, warning=FALSE}

#Mean Error and APE 

mean(boulder.test$price.abserror, na.rm = T)
mean(boulder.test$price.ape, na.rm = T)
mean(boulder.test$price.predict, na.rm = T)




ggplot(data = boulder.test) +
  geom_point(aes(x = price, y = price.abserror)) +
  labs(title = "Figure XX Observed Sale Price and Absolute Error") +
  plotTheme()

ggplot(data = boulder.test) +
  geom_point(aes(x = price, y = price.ape)) +
  labs(title = "Figure XX: Observed Sale Price with Absolute Percent Error") +
  plotTheme()

```



## D.	Test Model
*Provide the results of your cross-validation tests. This includes mean and standard deviation MAE.*

*Do 100 folds and plot your cross-validation MAE as a histogram.*

### 1. K-Fold Cross-Validation Test 

Testing for generalization 
Comparing mean average error of K-fold output with our model above that we trained 

```{r k-fold cross-validation}

fitControl <- trainControl(
  method = "cv", 
  number = 100)

set.seed(825)


fit.cv =
  train(price ~ .,
    data = boulder.train %>% select_v(.),
    method = "lm", trControl = fitControl, na.action = na.pass)


fit.cv


```

```{r test_cv}


training.results = 
  data.frame(
    fm = c()
    
  )

fit.cv.predict.0 <-
  boulder.predict.0 %>%
  mutate(regression = "Baseline Regression",
         price.predict  = predict(fit.cv, boulder.predict), 
         price.error    = price.predict - price, 
         price.abserror = abs(price.predict - price), 
         price.ape      = price.abserror / price) %>%  
  filter(price < 5000000)

fold75 <- fit.cv$control$indexOut$Resample075
reg75 <- fit.cv.predict.0[fold75,c("price", "price.predict")]
reg75.test <-
  reg75 %>%
  mutate(price.error = price.predict - price, 
         price.abserror = abs(price.predict - price), 
         price.ape = price.abserror / price) %>% 
  filter(price < 5000000) 

fit.cv.rs.min <- fit.cv$resample[75,]
fit.cv.rs.min$MAPE <- mean(reg75.test$price.ape)


round_df <- function(x, digits) {
    numeric_columns <- sapply(x, mode) == 'numeric'
    x[numeric_columns] <-  round(x[numeric_columns], digits)
    x
}

fit.cv.rs.min <- round_df(fit.cv.rs.min, 2)

library(kableExtra)


fit.cv.rs.min <- fit.cv$resample[75,]
fit.cv.rs.min %>%                     
  gather(Variable, Value) %>%
  group_by(Variable) %>%
    spread(Variable, Value) %>%
    kable(caption = "Table XXX: Regression Results of One Test Set") %>%
   kable_classic(full_width = F, html_font = "Cambria")



```

### 2. Histogram of MAE

```{r histogram of MAE, message=FALSE, warning=FALSE}

ggplot(fit.cv$resample, aes(x=MAE)) +
  geom_histogram() +
  labs(title = "Figure XX: Mean Average Error in Cross Validation Tests") +
  plotTheme()

```

*Is your model generalized to new data?*

## E. Plot Predicted Prices
*Plot predicted prices as a function of observed prices*

```{r prediction_plot, message=FALSE, warning=FALSE}

predictedprices <- boulder.data %>%
  mutate(prediction = predict(fit.cv, boulder.data))


ggplot() +
  geom_sf(data = XXXX, fill = "gray90", colour = "white") +
    geom_sf(data = XXXX, fill = "XXXX", colour = "XXXXX") +
  geom_sf(data = predictedprices, aes(colour = q5(prediction))) +
 scale_colour_manual(values = palette5) +
 labs(title = "Figure XXX: predicted House Price Values", subtitle = "Boulder County, CO") +
 # facet_wrap(~toPredict) +
  mapTheme()




```

## F. Map Predictions

### 1. Map of Residuals (Test)
*1. Provide a map of your residuals for your test set*
*2. Include a Moran’s I test*
*3. Plot of the spatial lag in errors.*

```{r Map of test set residuals}

library(modelr)

boulder.test$resid <- 
  boulder.test %>%
  as_data_frame() %>%
  add_residuals(., boulder.train.lm, var = "resid") %>%
  dplyr::select(resid, Folio) %>%
  pull(resid)


ggplot() +
geom_sf(data = XXXX, fill = "gray90", colour = "XXX") +
    geom_sf(data = XXXX, fill = "XXXX", colour = "XXXX") +
  geom_sf(data = boulder.test, aes(colour = q5(resid))) +
  scale_colour_manual(values = palette5) +
 labs(title = "Figure XXX: Test Set Residual Errors", subtitle = "XXXXX") +
  mapTheme()


```

